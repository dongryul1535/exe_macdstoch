#!/usr/bin/env python3
"""
DART ì„ì›Â·ì£¼ìš”ì£¼ì£¼ íŠ¹ì •ì¦ê¶Œë“±ì†Œìœ ìƒí™©ë³´ê³ ì„œ + NH MTS-style MACD+Stochastic ì•Œë¦¼ ë´‡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1) ì˜¤ëŠ˜(í•œêµ­ì‹œê°„) ê³µì‹œëœ "ì„ì›Â·ì£¼ìš”ì£¼ì£¼íŠ¹ì •ì¦ê¶Œë“±ì†Œìœ ìƒí™©ë³´ê³ ì„œ"ë§Œ í•„í„°ë§
2) í•´ë‹¹ ê¸°ì—… ì¢…ëª©ì½”ë“œë¡œ ê°€ê²© ì¡°íšŒ (FinanceDataReader â†’ yfinance fallback å¯ ì¶”ê°€ ê°€ëŠ¥)
3) **NH ë‚˜ë¬´ MTS ë°©ì‹ Composite K / D ê³„ì‚°**
   - MACD_raw = EMA(12) - EMA(26)
   - MACD_norm = 14ê¸°ê°„ ìŠ¤í† ìºìŠ¤í‹±(0~100)í™” í›„ 3ê¸°ê°„ ìŠ¤ë¬´ë”©
   - Slow%K   = ê°€ê²©ê¸°ë°˜ Stochastic(14,3)
   - Composite K = (MACD_norm + Slow%K) / 2
   - Composite D = SMA(Composite K, 3)
4) ê³¨ë“ /ë°ë“œ í¬ë¡œìŠ¤ íƒì§€ â†’ í…”ë ˆê·¸ë¨ í…ìŠ¤íŠ¸ + ì°¨íŠ¸ ì´ë¯¸ì§€ ì „ì†¡
5) GitHub Actionsì—ì„œ ì£¼ê¸° ì‹¤í–‰

ENV
----
- TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, DART_API_KEY (í•„ìˆ˜)
- DART_OFFSET_DAYS: 0=ì˜¤ëŠ˜, 1=ì–´ì œ ... (ê¸°ë³¸ 0)
- SAVE_CSV=true  â†’ CSV ì €ì¥
- FONT_PATH=fonts/NanumGothic.ttf  â†’ í•œê¸€ í°íŠ¸

requirements.txt (ì˜ˆì‹œ)
-----------------------
numpy>=1.24.0
pandas>=1.5.3
requests>=2.28.2
finance-datareader>=0.9.59
yfinance>=0.2.40
matplotlib>=3.8.4
"""

import os
import io
import zipfile
import logging
import datetime as dt
from typing import List, Optional, Dict
import time
import xml.etree.ElementTree as ET

import numpy as np
import pandas as pd
import requests
import FinanceDataReader as fdr

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.dates import DateFormatter
import matplotlib.font_manager as fm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
KST = dt.timezone(dt.timedelta(hours=9))
TODAY = dt.datetime.now(KST).strftime('%Y%m%d')

TOKEN    = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID  = os.getenv("TELEGRAM_CHAT_ID")
DART_KEY = os.getenv("DART_API_KEY")
SAVE_CSV = os.getenv("SAVE_CSV",   "false").lower() == "true"
FONT_PATH  = os.getenv("FONT_PATH", "")
DART_OFFSET_DAYS = int(os.getenv("DART_OFFSET_DAYS", "0"))

if not (TOKEN and CHAT_ID and DART_KEY):
    raise SystemExit("í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, DART_API_KEY")

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# Font
if FONT_PATH and os.path.exists(FONT_PATH):
    fm.fontManager.addfont(FONT_PATH)
    font_prop = fm.FontProperties(fname=FONT_PATH)
    plt.rcParams['font.family'] = font_prop.get_name()
    plt.rcParams['axes.unicode_minus'] = False
else:
    font_prop = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DART / KRX ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
DART_URL = "https://opendart.fss.or.kr/api"
CORP_CODE_URL = f"{DART_URL}/corpCode.xml"

_cache_corp_map: Optional[Dict[str, Dict[str,str]]] = None

def load_corp_map() -> Dict[str, Dict[str, str]]:
    """{stock_code: {corp_code, corp_name}} ë§¤í•‘ ìƒì„±"""
    global _cache_corp_map
    if _cache_corp_map is not None:
        return _cache_corp_map
    params = {'crtfc_key': DART_KEY}
    resp = requests.get(CORP_CODE_URL, params=params, timeout=20)
    zf = zipfile.ZipFile(io.BytesIO(resp.content))
    xml_bytes = zf.read(zf.namelist()[0])
    root = ET.fromstring(xml_bytes)
    mapping = {}
    for corp in root.findall('list'):
        stock = corp.findtext('stock_code') or ''
        corp_code = corp.findtext('corp_code') or ''
        corp_name = corp.findtext('corp_name') or ''
        if stock:
            stock = stock.zfill(6)
            mapping[stock] = {"corp_code": corp_code, "corp_name": corp_name}
    _cache_corp_map = mapping
    return mapping

# ì´ë¦„ ë§¤í•‘ (KRX,KOSDAQ)
_krx = fdr.StockListing('KRX')[['Code','Name']]
_kq  = fdr.StockListing('KOSDAQ')[['Code','Name']]
NAME_MAP = {f"{r.Code}.KS": r.Name for _, r in _krx.iterrows()}
NAME_MAP.update({f"{r.Code}.KQ": r.Name for _, r in _kq.iterrows()})

def get_name(code: str) -> str:
    return NAME_MAP.get(code, code)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µì‹œ ìˆ˜ì§‘ & í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
TARGET_KEYWORDS = ["ì„ì›", "ì£¼ìš”ì£¼ì£¼", "íŠ¹ì •ì¦ê¶Œë“±ì†Œìœ ìƒí™©ë³´ê³ ì„œ"]
EXCLUDE_KEYWORDS = ["ì •ì •", "ë³€ê²½", "ì·¨ì†Œ", "ì‹ ê·œì„ ì„", "í•´ì„", "ì‚¬ì„", "í‡´ì„", "ì„ì›í˜„í™©", "ì˜ê²°ê¶Œ"]

def ymd(days_offset: int = 0) -> str:
    return (dt.datetime.now(KST) - dt.timedelta(days=days_offset)).strftime('%Y%m%d')

def fetch_list(days_offset: int = 0) -> List[dict]:
    """íŠ¹ì • ë‚ ì§œ(ì˜¤í”„ì…‹) ê³µì‹œ ëª©ë¡ (ë‹¤ì¤‘ í˜ì´ì§€)"""
    bgn_de = ymd(days_offset)
    end_de = bgn_de
    all_rows: List[dict] = []
    for page in range(1, 11):
        params = {
            'crtfc_key': DART_KEY,
            'bgn_de': bgn_de,
            'end_de': end_de,
            'page_no': page,
            'page_count': 100
        }
        r = requests.get(f"{DART_URL}/list.json", params=params, timeout=20)
        if r.status_code != 200:
            logging.warning("DART list HTTP %s", r.status_code)
            break
        data = r.json()
        if data.get('status') != '000':
            logging.warning("DART list status %s", data.get('status'))
            break
        rows = data.get('list', [])
        all_rows.extend(rows)
        if len(rows) < 100:
            break
        time.sleep(0.3)
    logging.info("%s ê³µì‹œ %dê±´ ìˆ˜ì§‘", bgn_de, len(all_rows))
    return all_rows

def is_target_report(report_nm: str) -> bool:
    name = (report_nm or "").replace('Â·', 'ã†')
    if not all(k in name for k in TARGET_KEYWORDS):
        return False
    if any(k in name for k in EXCLUDE_KEYWORDS):
        return False
    return True

def filter_target_disclosures(rows: List[dict]) -> List[dict]:
    results = []
    for item in rows:
        if is_target_report(item.get('report_nm', '')):
            results.append(item)
    logging.info("íƒ€ê¹ƒ ê³µì‹œ %dê±´", len(results))
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œì„¸/ì§€í‘œ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
try:
    import yfinance as yf
except Exception:
    yf = None

def fetch_daily(symbol: str, days: int = 180) -> Optional[pd.DataFrame]:
    end = dt.datetime.now()
    start = end - dt.timedelta(days=days)
    # ìš°ì„  FDR
    try:
        df = fdr.DataReader(symbol, start, end)
        if not df.empty:
            df = df.reset_index()
            df.rename(columns=str.capitalize, inplace=True)
            return df[['Date','Open','High','Low','Close','Volume']]
    except Exception:
        pass
    # yfinance fallback
    if yf is not None:
        try:
            ydf = yf.download(f"{symbol}.KS", start=start.date(), end=end.date(), progress=False)
            if not ydf.empty:
                ydf = ydf.rename(columns=str.title).reset_index()
                return ydf[['Date','Open','High','Low','Close','Volume']]
        except Exception:
            pass
    return None

# NH ìŠ¤íƒ€ì¼ Composite

def add_composites(df: pd.DataFrame,
                   fast: int = 12, slow: int = 26,
                   k_window: int = 14, k_smooth: int = 3,
                   d_smooth: int = 3, use_ema: bool = True,
                   clip: bool = True) -> pd.DataFrame:
    close, high, low = df['Close'], df['High'], df['Low']

    ema_fast = close.ewm(span=fast, adjust=False).mean()
    ema_slow = close.ewm(span=slow, adjust=False).mean()
    macd_raw = ema_fast - ema_slow

    macd_min = macd_raw.rolling(k_window, min_periods=1).min()
    macd_max = macd_raw.rolling(k_window, min_periods=1).max()
    macd_norm = (macd_raw - macd_min) / (macd_max - macd_min).replace(0, np.nan) * 100
    macd_norm = macd_norm.fillna(50)
    if k_smooth > 1:
        macd_norm = macd_norm.ewm(span=k_smooth, adjust=False).mean() if use_ema \
            else macd_norm.rolling(k_smooth, min_periods=1).mean()

    ll = low.rolling(k_window, min_periods=1).min()
    hh = high.rolling(k_window, min_periods=1).max()
    k_raw = (close - ll) / (hh - ll).replace(0, np.nan) * 100
    k_raw = k_raw.fillna(50)
    slow_k = (k_raw.ewm(span=k_smooth, adjust=False).mean() if (k_smooth > 1 and use_ema)
              else k_raw.rolling(k_smooth, min_periods=1).mean() if k_smooth > 1 else k_raw)

    comp_k = (macd_norm + slow_k) / 2.0
    comp_d = comp_k.rolling(d_smooth, min_periods=1).mean() if d_smooth > 1 else comp_k

    if clip:
        comp_k = comp_k.clip(0, 100)
        comp_d = comp_d.clip(0, 100)

    df['CompK'] = comp_k
    df['CompD'] = comp_d
    df['Diff']  = comp_k - comp_d
    return df

def detect_cross(df: pd.DataFrame, ob: int = 80, os: int = 20) -> Optional[str]:
    if len(df) < 2:
        return None
    prev, curr = df['Diff'].iloc[-2], df['Diff'].iloc[-1]
    prev_k = df['CompK'].iloc[-2]
    if prev <= 0 < curr:
        return 'BUY' if prev_k < os else 'BUY_W'
    if prev >= 0 > curr:
        return 'SELL' if prev_k > ob else 'SELL_W'
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def make_chart(df: pd.DataFrame, code: str) -> str:
    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(9,6), sharex=True, gridspec_kw={'height_ratios':[3,1]})
    name = get_name(code)
    ax1.plot(df['Date'], df['Close'], label='ì¢…ê°€')
    ax1.plot(df['Date'], df['Close'].rolling(20).mean(), linestyle='--', label='MA20')
    ax1.set_title(f"{code} ({name})", fontproperties=font_prop)
    ax1.legend(prop=font_prop)

    ax2.plot(df['Date'], df['CompK'], color='red', label='MACD+Slow%K')
    ax2.plot(df['Date'], df['CompD'], color='purple', label='MACD+Slow%D')
    ax2.axhline(20, color='gray', linestyle='--', linewidth=0.5)
    ax2.axhline(80, color='gray', linestyle='--', linewidth=0.5)
    ax2.set_ylim(0, 100)
    ax2.set_title('MACD+Stochastic (NH Style)', fontproperties=font_prop)
    ax2.legend(prop=font_prop)
    ax2.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))

    fig.autofmt_xdate()
    fig.tight_layout()
    path = f"{code}_chart.png"
    fig.savefig(path, dpi=110)
    plt.close(fig)
    return path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í…”ë ˆê·¸ë¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def tg_text(msg: str):
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    for chunk in [msg[i:i+3500] for i in range(0, len(msg), 3500)]:
        try:
            requests.post(url, json={'chat_id': CHAT_ID, 'text': chunk}, timeout=15)
        except Exception as e:
            logging.warning("í…ìŠ¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨: %s", e)
        time.sleep(0.3)

def tg_photo(path: str, caption: str = ''):
    url = f"https://api.telegram.org/bot{TOKEN}/sendPhoto"
    try:
        with open(path, 'rb') as f:
            requests.post(url, data={'chat_id': CHAT_ID, 'caption': caption}, files={'photo': f}, timeout=30)
    except Exception as e:
        logging.warning("ì‚¬ì§„ ì „ì†¡ ì‹¤íŒ¨: %s", e)
    time.sleep(0.3)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def main():
    logging.info("==== ì‹œì‘: %s ====", dt.datetime.now(KST))

    corp_map = load_corp_map()
    rows = fetch_list(DART_OFFSET_DAYS)
    targets = filter_target_disclosures(rows)

    if not targets:
        logging.info("íƒ€ê¹ƒ ê³µì‹œ ì—†ìŒ")
        tg_text(f"{ymd(DART_OFFSET_DAYS)} ì„ì›Â·ì£¼ìš”ì£¼ì£¼ íŠ¹ì •ì¦ê¶Œë“±ì†Œìœ ìƒí™©ë³´ê³ ì„œ ê³µì‹œ ì—†ìŒ")
        return

    alerts: List[str] = []

    for item in targets:
        corp_name = item.get('corp_name', '')
        corp_code = item.get('corp_code', '')
        rcept_dt  = item.get('rcept_dt', '')
        rcept_no  = item.get('rcept_no', '')
        report_nm = item.get('report_nm', '')

        # stock_code ì°¾ê¸°
        stock_code = None
        for scode, info in corp_map.items():
            if info['corp_code'] == corp_code:
                stock_code = scode
                break
        if not stock_code:
            logging.warning("%s(%s) stock_code ì—†ìŒ", corp_name, corp_code)
            continue

        suffix = '.KS' if f"{stock_code}.KS" in NAME_MAP else '.KQ'
        code = f"{stock_code}{suffix}"

        df = fetch_daily(stock_code)
        if df is None or len(df) < 40:
            logging.warning("%s ë°ì´í„° ë¶€ì¡±", code)
            continue

        df = add_composites(df)
        sig = detect_cross(df)

        caption = (f"{corp_name} ({code})\n"
                   f"ğŸ“„ {report_nm}\n"
                   f"ğŸ“… {rcept_dt[:4]}-{rcept_dt[4:6]}-{rcept_dt[6:8]}\n"
                   f"ğŸ”— DART: https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}")
        if sig:
            caption = f"[{sig}]\n" + caption
            alerts.append(f"{sig} - {corp_name} ({code})")

        img = make_chart(df.tail(120), code)
        tg_photo(img, caption=caption)
        if SAVE_CSV:
            df.to_csv(f"{code}_hist.csv", index=False)

    if alerts:
        tg_text("\n".join(alerts))
    else:
        tg_text("ì‹ í˜¸ ì—†ìŒ (ê³¨ë“ /ë°ë“œ í¬ë¡œìŠ¤ ë¯¸ë°œìƒ)")

    logging.info("==== ì¢…ë£Œ ====")


if __name__ == '__main__':
    main()
